\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage[a4paper, total={6in, 8in}]{geometry}

\title{\vspace{-4.0cm}Sweeping Preconditioner with Moving Perfectly Matched Layer for the Helmholtz Equation}
\author{Alex Bocchieri}
\date{}


\begin{document}
\maketitle

\section{Introduction}
The Helmholtz equation defined as $\Delta u(x) + \frac{\omega^2}{c^2(x)}u(x)=f(x)$ 
is a time-independent factorization of the wave equation, where $w$ is angular 
frequency, $c(x)$ is the velocity field, and $f(x)$ is the external force. 
Many different approaches exist for numerically solving the Helmholtz equation 
in a discretized system. 

Boundary conditions must be handled properly when numerically solving a 
wave equation on a finite grid. The Sommerfeld condition for waves that propagate to an 
infinite distance is not satisfied when computing on a finite domain. This leads to 
non-physical reflections at the boundaries \cite{erlangga2008advances}. The typical 
correction is to impose absorbing boundary conditions. The perfectly matched layer (PML) 
\cite{berenger1994perfectly} is one common method for absorbing waves at the boundaries. 
The PML method adds a damping region around the original domain (or within it) and 
accordingly modifies the equation we are solving. The PML reduces non-physical
reflections and provides a more favorable system to solve for, but it also adds
computational cost.

% \textcolor{red}{need higher $n$ for higher frequency in previous methods.}

Certain iterative methods can be applied for solving the Helmholtz equation. They require 
preconditioning due to the Helmholtz system's indefiniteness. The methods in 
\cite{engquist2011pml} and \cite{engquist2011matrix} apply a sweeping preconditioner and
iteratively solve the system using GMRES \cite{saad1986gmres}. Both methods use the PML to arrive
at initial system. Their key observation is that the system can be factorized into a form
where block matrices correspond to the Helmholtz Green's function and are highly compressible.
In \cite{engquist2011matrix}, these matrices are approximated using the hierarchical matrices. 
In \cite{engquist2011pml}, these matrices are represented by inverting a Helmholtz system with 
a moving PML. In 2D, both methods take $O(N)$ time. %, thereby improving on direct methods described in the following paragraph.

%%%%%%%%%%% commented this out %%%%%%%%%%
\iffalse
The frontal solver \cite{irons1970frontal} is a direct method for solving sparse 
systems in a manner similar to Gaussian elimination. The frontal solver extracts 
small blocks (fronts) within the sparse $A$ matrix for eliminating variables/equations. 
The multifrontal solver \cite{duff1983multifrontal} extends this method to process 
multiple independent fronts in parallel. For a 2D Helmholtz problem with $N=n^2$ unknowns, 
the multifrontal method takes $O(N^{3/2})$ time and $O(N \log N)$ space. The method 
becomes inefficient for 3D problems with $N=n^3$ unknowns, where it takes $O(N^2)$ 
time and $O(N^{4/3})$ space \cite{engquist2011matrix}. Direct methods also suffer 
from fill-in \cite{erlangga2008advances} that occurs during the Gaussian elimination process.
\fi

In this project, I implement the sweeping preconditioner with the moving PML as 
described in \cite{engquist2011pml}. The general method is as follows.
Work in the 2D domain $(x_1, x_2) \in (0,1)^2$ discretized on an $n$ x $n$ grid where the number 
of grid points $N=n^2$. 
Assume Dirichlet zero boundary conditions at $x_2=1$. Approximations to the Sommerfeld 
boundary conditions are imposed on the other three sides (absorbing layers) using a PML 
(equations provided in the paper).
A 5-point stencil is used to generate the $A$ matrix, which can be block-$LDL^T$-factorized. 
This factorization eliminates unknowns layer by layer, starting from $x_2=0$ (hence ``sweeping 
factorization''). 
Inverting the factorization of $A$ can be used to solve for $u$ as described in Algorithms 
2.1 and 2.2 in the paper. However, this takes $O(N^{3/2})$, which is no better than a 
multifrontal (direct) method. On closer observation, $A^{-1}$ truncated to the first $m$ layers 
approximates the discrete half-space Green's function of the Helmholtz equation with 
zero boundary conditions. Similarly, the $m$th block matrix (denoted as $T_m$) in the 
factorization's diagonal corresponds to the same Green's function restricted to $x_2=mh$
with zero boundary at $x_2=(m+1)h$. $T_m$ maps an external force loaded on the $m$th layer 
to the solution in the $m$th layer. Therefore, for approximating $T_m$, the PML can be 
moved up from $x_2=0$ to $x_2=mh$. The approximation to $T_m$ can be solved for efficiently
in a small subgrid where the moved PML lies (by the $m$th layer) and applied
efficiently. 
In the paper, Algorithm 2.3 describes the sweeping factorization of $A$ with moving PML, and 
Algorithm 2.4 describes the preconditioner $M$ using the sweeping factorization with moving PML, 
where $M$ is an approximate inverse of $A$. $u$ is solved for in the preconditioned system 
$MAu=Mf$ using GMRES.
Overall, the algorithm solves $\Delta u(x) + \frac{(\omega+i\alpha)^2}{c^2(x)}u(x)=f(x)$ in 
about $O(N)$ time, where $\alpha$ is a small constant ($\alpha$=2).


Constant value $C$ is important. I had to tune this constant for each example setup to obtain a 
proper solution. I would try many values for $C$, and most ended up giving me a garbage solution. 
When I found a $C$ that gave me a visually correct solution, the solution values were either very
large (e.g. abut $1e13$), or they were close to 0. Solutions close to 0 make more sense, and I
tried to find $C$ values that resulted in such a solution. Furthermore, visually
correct solutions with very large numbers took GMRES significantly longer to solve for than
solutions with small numbers. For example, when I run the solver with $N=255^2$, velocity 
field 1, forcing function 2, and $C=61$, GMRES takes about 0.75 seconds to compute a 
small-numbered solution. When I use $C=62$, GMRES takes about 1.5 seconds to compute a 
large-numbered solution (that still looks visually correct). Similarly for $N=1023^2$, the 
times were about 13.0 seconds and 25.6 seconds for $C=100.6$ and $C=100$ respectively. 
\textcolor{red}{I also noticed examples where the same $C$ value produced a large-numbered solution on my 
MacBook Pro and a small-numbered solution on my Linux desktop.} This suggests the method is very 
sensitive to choosing an appropriate value for $C$.




\bibliographystyle{plain}
\bibliography{bibliography}


\end{document}
